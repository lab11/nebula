{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedule generation\n",
    "\n",
    "Now that we have simulation data on the interactions between sensors and mules, we want to generate an upload schedule based on sampling frequency and batched updates.\n",
    "\n",
    "We will collect the following thingomaboobers:\n",
    "\n",
    "`schedule.csv`\n",
    "\n",
    "| sensor_id | mule_id | sample_time | pickup_time | batch_time | data_length |\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| i = 0, ..., 999 | j = 0, ..., 99 | seconds | seconds | seconds | bytes |\n",
    "\n",
    "where `sample_time` is the time that the sensor generated the sample, `pickup_time` is the time that the mule walked into the sensor's range and picked up the packet (which is also the upload time for a non-privacy-preserving setup), and `batch_time` is the time that the packet would be uploaded if it the upload time is delayed and uploads are batched into constant sized chunks for privacy reasons. \n",
    "\n",
    "We will also have the following parameters that can be twiggled:\n",
    "\n",
    "- `number of mules` - number (integer) of mules that are included in the simulation\n",
    "- `number of sensors` - number (integer) of sensors that are included in the simulation\n",
    "- `advertisement period` - time (in seconds) between each sensor's BLE advertisement used to discover nearby mules\n",
    "- `connection time` - time (in seconds) needed for a connection to form before data can be transferred\n",
    "- `ble throughput` - rate (in bytes per second) of data transfer from a sensor to a mule\n",
    "- `sample period` - time (in seconds) between each sample that a sensor takes\n",
    "- `sample length` - size (in bytes) of the samples a sensor transfers to a mule\n",
    "- `batch period` - time (in seconds) between each batch the mule uploads\n",
    "- `batch length` - size (in bytes) of the batches a mule uploads to the cloud\n",
    "\n",
    "I think this is all we need for now to evaluate the baseline and Express. We assume that each sensor connects to only one mule at a time, while a mule can connect to an arbitrary number of sensors at a time. After a sensor connects to a mule, it stays connected and transfers data as long as the mule is within range. Once the mule leaves the sensor's range, the sensor immediately starts advertisements and looks for a new mule to form a connection with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters.\n",
    "num_mules = 100\n",
    "num_sensors = 1000\n",
    "advertisement_period = 2.0 # seconds\n",
    "connection_time = 1.5 # seconds\n",
    "ble_throughput = 125000.0 # bytes per second = 1 Mbps\n",
    "sample_period = 10.0 # seconds\n",
    "sample_length = 128 # bytes\n",
    "batch_period = 600.0 # seconds = 10 minutes\n",
    "batch_length = 100000 # bytes = 100 KB\n",
    "\n",
    "# Set save file.\n",
    "save_file = 'prob_data/schedule.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data files and downsample as necessary.\n",
    "interaction_df = pd.read_csv('prob_data/interactions.csv')\n",
    "smol_interactions = interaction_df.loc[(interaction_df['sensor_id'] < num_sensors) & \n",
    "                                       (interaction_df['mule_id'] < num_mules)]\n",
    "# Sort the interactions by interaction time.\n",
    "smol_interactions = smol_interactions.sort_values('interaction_time')\n",
    "\n",
    "# Calculate some useful numbers.\n",
    "time_per_sample = sample_length / ble_throughput \n",
    "samples_per_batch = math.floor(batch_length / sample_length)\n",
    "\n",
    "# Start bookkeeping.\n",
    "next_samples = [0 for i in range(num_sensors)] # Accumulates samples for each sensor to send.\n",
    "cur_end_times = [0.0 for i in range(num_sensors)] # Keeps track of the latest action time for each sensor.\n",
    "next_batches = [0 for i in range(num_mules)] # Keeps track of which batch each mule is on.\n",
    "next_batch_lengths = [0 for i in range(num_mules)] # Keeps track of the size of each accumulating batch.\n",
    "schedule = [] # Records our resulting upload schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each row of sensor-mule interactions.\n",
    "for index, row in smol_interactions.iterrows():\n",
    "    # Grab the sensor and mule used in this interaction.\n",
    "    cur_sensor = int(row['sensor_id'])\n",
    "    cur_mule = int(row['mule_id'])\n",
    "    \n",
    "    # Grab some stats for this sensor.\n",
    "    cur_end_time = cur_end_times[cur_sensor]\n",
    "    \n",
    "    # If the sensor has already taken actions beyond this time, ignore this row.\n",
    "    new_end_time = row['interaction_time'] + row['interaction_duration']\n",
    "    if cur_end_time >= new_end_time:\n",
    "        continue\n",
    "    \n",
    "    # Otherwise, we advertise and attempt to start a connection.\n",
    "    time_passed = max(0.0, row['interaction_time'] - cur_end_time)\n",
    "    new_start_time = cur_end_time + math.ceil(time_passed / advertisement_period) * advertisement_period\n",
    "    # If there is not enough time for a connection, we waste some time and move on with our lives.\n",
    "    cur_end_time = new_start_time + connection_time\n",
    "    if cur_end_time >= new_end_time:\n",
    "        cur_end_times[cur_sensor] = new_end_time\n",
    "        continue\n",
    "    # Otherwise, we successfully connected to the mule and have time to do stuff.\n",
    "    \n",
    "    # The first thing we do is dump a bunch of accumulated samples onto the mule as fast as possible\n",
    "    # as long as the mule is connected.\n",
    "    next_sample = next_samples[cur_sensor]\n",
    "    next_batch_length = next_batch_lengths[cur_mule]\n",
    "    next_batch = next_batches[cur_mule]\n",
    "    while next_sample * sample_period <= cur_end_time and cur_end_time + time_per_sample <= new_end_time:\n",
    "        cur_end_time += time_per_sample\n",
    "        next_batch_length += 1\n",
    "        # If the current batch of samples is full, move on to the next batch.\n",
    "        if next_batch_length > samples_per_batch:\n",
    "            next_batch += 1\n",
    "            next_batch_length = 1\n",
    "        # Send the sample.\n",
    "        schedule.append([cur_sensor,                  # sensor_id\n",
    "                         cur_mule,                    # mule_id \n",
    "                         next_sample * sample_period, # sample_time\n",
    "                         cur_end_time,                # pickup_time\n",
    "                         next_batch * batch_period,   # batch_time\n",
    "                         sample_length])              # data_length\n",
    "        next_sample += 1\n",
    "    \n",
    "    # After we have done that, we continue the connection and send new samples as they come in.\n",
    "    # !! If sensors are dense, samples are frequent, and samples per batch is small, this may result in\n",
    "    # !! some sensors having upload priority over other sensors in a way that does not respect the \n",
    "    # !! chronological order of samples received by the mule.\n",
    "    # !! I am not entirely sure how to fix this, so I will ignore it for now. \n",
    "    while next_sample * sample_period + time_per_sample <= new_end_time:\n",
    "        next_batch_length += 1\n",
    "        # If the current batch of samples is full, move on to the next batch.\n",
    "        if next_batch_length > samples_per_batch:\n",
    "            next_batch += 1\n",
    "            next_batch_length = 1\n",
    "        # Send the sample.\n",
    "        schedule.append([cur_sensor,                                    # sensor_id\n",
    "                         cur_mule,                                      # mule_id \n",
    "                         next_sample * sample_period,                   # sample_time\n",
    "                         next_sample * sample_period + time_per_sample, # pickup_time\n",
    "                         next_batch * batch_period,                     # batch_time\n",
    "                         sample_length])                                # data_length\n",
    "        next_sample += 1\n",
    "    \n",
    "    # Finally, once we are done sending all the samples that can be sent, we close out the interaction\n",
    "    # and update the bookkeeping lists as necessary.\n",
    "    next_samples[cur_sensor] = next_sample\n",
    "    cur_end_times[cur_sensor] = new_end_time\n",
    "    next_batches[cur_mule] = next_batch\n",
    "    next_batch_lengths[cur_mule] = next_batch_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our results\n",
    "with open(save_file, 'w') as f:\n",
    "    # Record parameters.\n",
    "    f.write('num_mules,num_sensors,advertisement_period,connection_time,ble_throughput,sample_period,sample_length,batch_period,batch_length\\n')\n",
    "    f.write('{},{},{},{},{},{},{},{},{}\\n'.format(num_mules,num_sensors,advertisement_period,connection_time,ble_throughput,sample_period,sample_length,batch_period,batch_length))\n",
    "    \n",
    "    # Record schedule.\n",
    "    f.write('sensor_id,mule_id,sample_time,pickup_time,batch_time,data_length\\n')\n",
    "    np.savetxt(f, schedule, delimiter=',')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['sensor_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mules = 100\n",
    "num_sensors = 1000\n",
    "advertisement_period = 2.0 # seconds\n",
    "connection_time = 1.5 # seconds\n",
    "ble_throughput = 125000.0 # bytes per second = 1 Mbps\n",
    "sample_period = 10.0 # seconds\n",
    "sample_length = 128 # bytes\n",
    "batch_period = 600.0 # seconds = 10 minutes\n",
    "batch_length = 100000 # bytes = 100 KB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
