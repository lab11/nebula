{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Mobility Attack\n",
    "\n",
    "This notebook captures the essense of our two-phase attack in reconstructing mobile trajectories from transmission metadata. Our attack is carried out on the campus of Peking University in Beijing, China across area that is 800m wide and 950m long. We simulated opportunistic connections between 60 stationary gateways and 12 mobile sensors, and collect metadata on connection times, gateway identity, and sensor identity.\n",
    "\n",
    "The first phase takes the collected metadata and assumes we have the knowledge of a few of the gateways' locations. In practice, this data is easy to acquire as a network provider simply by deploying a few gateways in opportune areas (ideally with high traffic). We then attempt to reconstruct the locations of all other gateways in the area. We compare our predictions against the ground truth location information to see how well we did.\n",
    "\n",
    "The second phase takes these predicted locations and reconstructs the mobile trajectories of the 12 sensors based on the sequence of gateways they connect to over time. We compare our predicted trajectory against the ground truth trajectory to see how well we did.\n",
    "\n",
    "By carrying out this attack, we demonstrate the feasibility of mining rich location data from minimal network metadata and sparse knowledge of gateway locations. As such information reveals personal activity patterns and can be used in subsequent deanonymization attacks, it is imperative to hide this information in subsequent deployments of opportunistic networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "This section loads and visualizes our ground truth gateway locations and sensor trajectories. \n",
    "\n",
    "TODO: basically do `visualizing_success` here.\n",
    "\n",
    "For the `sensor_df`, `norm_secs (secs)` are sensor values stitched together, `time (days)` reflects the difference. But starts at 0. `time (secs)` same as days but in seconds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1\n",
    "\n",
    "We start this phase with knowledge of the locations of a few (~3) gateways. Using this knowledge along with the information from the metadata, we construct relative distances between gateways close to each other. We make the simplifying assumption that the sensors move at a constant speed.\n",
    "\n",
    "Lines that can be edited to provide qualitatively different results will be marked with a `# !!` comment for easier idenfitication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the libraries.\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import least_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [01:05,  3.52it/s]"
     ]
    }
   ],
   "source": [
    "## Construct a matrix of pairwise distances. This matrix may be sparse.\n",
    "\n",
    "# This is the list of identifiers for the gateways that we know the positions of.\n",
    "known_ids = [21, 25, 47, 38, 7, 46, 2, 36, 10, 53, 34, 45, 28, 48] # !!\n",
    "num_known = len(known_ids)\n",
    "\n",
    "# Load in the ground truth positions of each stationary gateway.\n",
    "truth_df = pd.read_csv('../smol_truth/sensors.csv')\n",
    "num_gateways = len(truth_df)\n",
    "\n",
    "# Iterate through all traces and generate distance matrices.\n",
    "dist_diffs_list = []\n",
    "unscaled_diffs_list = []\n",
    "agg_speed = 0\n",
    "for sensor_path in tqdm(glob.iglob('../smol_sim/chopped_mules/*.csv')):\n",
    "    # Import the simulated mobile sensor connection metadata.\n",
    "    sensor_df = pd.read_csv(sensor_path)\n",
    "\n",
    "    # Calculate real-time seconds to avoid aggressive time-skips.\n",
    "    secs_per_day = 86400\n",
    "    sensor_df['time (secs)'] = (sensor_df['time (days)'] - sensor_df['time (days)'].iloc[0]) * secs_per_day\n",
    "\n",
    "    # Subsample the connection data to take samples that are wider apart in time.\n",
    "    sample_period = 8 # !!\n",
    "    smol_df = sensor_df.loc[(sensor_df['time (secs)'].round() % sample_period) == 0]\n",
    "\n",
    "    # Construct lists that hold the times taken to travel between each pair of gateways.\n",
    "    time_diff_lists = [[[] for j in range(num_gateways)] for i in range(num_gateways)]\n",
    "    # Do not consider relations between gateways further than cap_time seconds apart.\n",
    "    cap_time = 2 * 60 # !!\n",
    "    for i in range(len(smol_df)-1):\n",
    "        cur_gateway = int(smol_df['sensor ID'].iloc[i])\n",
    "        cur_time = smol_df['time (secs)'].iloc[i]\n",
    "\n",
    "        j = 1\n",
    "        next_gateway = int(smol_df['sensor ID'].iloc[i+j])\n",
    "        next_time = smol_df['time (secs)'].iloc[i+j]\n",
    "        time_diff = next_time - cur_time\n",
    "\n",
    "        while time_diff < cap_time:\n",
    "            time_diff_lists[cur_gateway][next_gateway].append(time_diff)\n",
    "            time_diff_lists[next_gateway][cur_gateway].append(time_diff)\n",
    "\n",
    "            j += 1\n",
    "            if i+j >= len(smol_df):\n",
    "                time_diff = cap_time\n",
    "            else:\n",
    "                next_gateway = int(smol_df['sensor ID'].iloc[i+j])\n",
    "                next_time = smol_df['time (secs)'].iloc[i+j]\n",
    "                time_diff = next_time - cur_time\n",
    "\n",
    "    # Consolidate the lists of times into a matrix of pairwise times between adjacent gateways.\n",
    "    # If we do not have any time values between two gateways, we use -1 to indicate no value.\n",
    "    time_diffs = np.full((num_gateways, num_gateways), -1.0)\n",
    "    for i in range(num_gateways-1):\n",
    "        for j in range(i+1, num_gateways):\n",
    "            times_list = time_diff_lists[i][j]\n",
    "            if len(times_list) > 0:\n",
    "                # We expect shorter times to be more representative of direct distance between gateways.\n",
    "                time_diffs[[i,j],[j,i]] = np.percentile(times_list, 5) # !!\n",
    "\n",
    "    # We use the time between known gateway positions to get an estimate for the speed of the mobile sensor.\n",
    "    true_dists = np.zeros((num_known, num_known))\n",
    "    for i in range(num_known):\n",
    "        for j in range(num_known):\n",
    "            dist = np.linalg.norm((truth_df[['x (m)', 'y (m)']].iloc[known_ids[i]] - truth_df[['x (m)', 'y (m)']].iloc[known_ids[j]]))\n",
    "            true_dists[[i,j],[j,i]] = dist\n",
    "    # Speed = distance / time. We assume the sensor travels at a constant speed.\n",
    "    speeds = np.divide(true_dists, time_diffs[known_ids,:][:,known_ids])\n",
    "    # If there is no time values to calculate speed with, we store this matrix and scale it later.\n",
    "    if (speeds <= 0).all():\n",
    "        unscaled_diffs_list.append(time_diffs)\n",
    "    else:\n",
    "        ave_speed = np.mean(speeds[speeds > 0]) # !!\n",
    "        agg_speed += ave_speed\n",
    "        # Using this estimate of speed, we can then estimate the pairwise distance matrix.\n",
    "        dist_diffs = time_diffs * ave_speed\n",
    "        dist_diffs_list.append(dist_diffs)\n",
    "\n",
    "# Calculate the average speed over all valid trajectories in order to scale trajectories that\n",
    "# we did not have enough information for. The assumption is that people in the same area move\n",
    "# at about the same speed, which is completely invalid, but hopefully works well enough in practice.\n",
    "'''\n",
    "ave_agg_speed = agg_speed / len(dist_diffs_list)\n",
    "for time_diffs in unscaled_diffs_list:\n",
    "    dist_diffs_list.append(time_diffs * ave_agg_speed)\n",
    "'''\n",
    "\n",
    "# Consolidate the relative distance matrices.\n",
    "dist_diffs = np.full((num_gateways, num_gateways), -1.0)\n",
    "for i in range(num_gateways-1):\n",
    "    for j in range(i+1, num_gateways):\n",
    "        val_list = []\n",
    "        for dist_mat in dist_diffs_list:\n",
    "            if dist_mat[i,j] > 0:\n",
    "                val_list.append(dist_mat[i, j])\n",
    "        if len(val_list) > 0:\n",
    "            dist_diffs[i,j] = np.median(val_list) # !!\n",
    "\n",
    "## Our pairwise distance matrix is called `dist_diffs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(unscaled_diffs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct predictions for the positions of each gateway by making iterative informed guesses.\n",
    "# Try num_attempts random beginnings and select the results with the minimum loss.\n",
    "num_attempts = 20\n",
    "losses = np.zeros((num_attempts, num_gateways))\n",
    "guess_mat = np.zeros((num_attempts, num_gateways, 2))\n",
    "for attempt in tqdm(range(num_attempts)):\n",
    "    # Randomly instantiate our position guesses within the area of interest.\n",
    "    guesses = np.vstack([np.random.uniform(low=0.0, high=800.0, size=num_gateways),\n",
    "                         np.random.uniform(low=0.0, high=950.0, size=num_gateways)]).T # !!\n",
    "    # Instantiate position guesses to be the middle of the area of interest.\n",
    "    #guesses = np.tile(np.array([[400, 475]]), [num_gateways, 1])\n",
    "\n",
    "    # Populate our guesses with the positions for our known gateways.\n",
    "    for known_id in known_ids:\n",
    "        guesses[known_id] = truth_df[['x (m)','y (m)']].loc[truth_df['sensor ID'] == known_id]\n",
    "    guess_mat[attempt] = guesses\n",
    "        \n",
    "    # Describe an error function to optimize.\n",
    "    dist_diff = None\n",
    "    def dist_err(point):\n",
    "        # Have less confidence near unknown gateway locations.\n",
    "        unknown_weight = 0.05 # !!\n",
    "        errs = []\n",
    "        for i in range(num_gateways):\n",
    "            # Expected distance based on metadata calculations.\n",
    "            dist = dist_diff[i]\n",
    "            if dist > 0:\n",
    "                # Current distance based on predicted positions.\n",
    "                point_dist = np.linalg.norm(point - guesses[i])\n",
    "                if i in known_ids:\n",
    "                    errs.append(point_dist - dist)\n",
    "                else:\n",
    "                    errs.append((point_dist - dist)*unknown_weight)\n",
    "        return np.array(errs)\n",
    "    \n",
    "    def known_err(point):\n",
    "        # Only give errors from known gateway positions.\n",
    "        errs = []\n",
    "        for i in range(num_gateways):\n",
    "            dist = dist_diff[i]\n",
    "            if dist > 0 and i in known_ids:\n",
    "                point_dist = np.linalg.norm(point - guesses[i])\n",
    "                errs.append(point_dist - dist)\n",
    "        if errs:\n",
    "            return np.array(errs)\n",
    "        return 0.0\n",
    "\n",
    "    # Guess based only on distances from known positions\n",
    "    for i in range(num_gateways):\n",
    "        if i in known_ids:\n",
    "            continue\n",
    "        dist_diff = dist_diffs[i]\n",
    "        guess_mat[attempt, i] = least_squares(known_err, guess_mat[attempt, i],\n",
    "                                              bounds=(np.array([0.0, 0.0]), np.array([800.0, 950.0])), # !!\n",
    "                                              loss='soft_l1').x # !!\n",
    "    \n",
    "    # Iteratively predict gateway positions to minimize the error function.\n",
    "    num_iterations = 10 # !!\n",
    "    for k in range(num_iterations):\n",
    "        for i in range(num_gateways):\n",
    "            # Do not need to predict the position of known gateways.\n",
    "            if i in known_ids:\n",
    "                continue\n",
    "            dist_diff = dist_diffs[i]\n",
    "            result = least_squares(dist_err, guess_mat[attempt, i],\n",
    "                                   bounds=(np.array([0.0, 0.0]), np.array([800.0, 950.0])), # !!\n",
    "                                   loss='soft_l1') # !!\n",
    "            guess_mat[attempt, i] = result.x\n",
    "            losses[attempt, i] = result.cost\n",
    "\n",
    "# Consolidate the predicted positions\n",
    "guess = np.array([guess_mat[opt, ind] for ind, opt in enumerate(np.argmin(losses, axis=0))])\n",
    "#guess = np.mean(guess_mat, axis=0)\n",
    "\n",
    "# Do one last optimization.\n",
    "for i in range(num_gateways):\n",
    "    if i in known_ids:\n",
    "        continue\n",
    "    dist_diff = dist_diffs[i]\n",
    "    guess[i] = least_squares(known_err, guess[i],\n",
    "                             bounds=(np.array([0.0, 0.0]), np.array([800.0, 950.0])), # !!\n",
    "                             loss='soft_l1').x # !!\n",
    "    \n",
    "## Our final guesses for gateway positions are in `guess`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyze our results numerically.\n",
    "\n",
    "errors = guess - truth_df[['x (m)', 'y (m)']]\n",
    "dist_errors = np.sort(np.linalg.norm(errors, axis=1))\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.title(\"Euclidean error of location predictions\")\n",
    "plt.xlabel(\"gateway IDs (resorted)\")\n",
    "plt.ylabel(\"error (m)\")\n",
    "plt.plot(dist_errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize the results.\n",
    "# Known gateway positions are black.\n",
    "# Ground truth (unknown) gateway positions are green.\n",
    "# Predicted (unknown) gateway positions are red.\n",
    "\n",
    "# Setup the figure.\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.title(\"Guessing Gateway Locations!\")\n",
    "plt.xlim([0, 800])\n",
    "plt.ylim([0, 950])\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "# Plot ground truth gateway positions.\n",
    "for index, row in truth_df.iterrows():\n",
    "    if index not in known_ids:\n",
    "        ax.add_patch(plt.Circle((row['x (m)'], row['y (m)']), row['radius (m)'], alpha = 0.4, color='g'))\n",
    "        plt.text(row['x (m)'], row['y (m)'], int(row['sensor ID']))\n",
    "\n",
    "# Plot known and predicted gateway positions.\n",
    "for index, pos in enumerate(guess):\n",
    "    if index in known_ids:\n",
    "        ax.add_patch(plt.Circle(pos, 15, alpha=0.6, color='k'))\n",
    "        plt.text(pos[0], pos[1], index)\n",
    "    else:\n",
    "        ax.add_patch(plt.Circle(pos, 15, alpha=0.4, color='r'))\n",
    "        plt.text(pos[0], pos[1], \"{}?\".format(index))\n",
    "\n",
    "# Display the figure.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2\n",
    "\n",
    "After predicting the gateway locations, we then do a mobile trajectory reconstruction attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_prediction(mobile_id='167', sample_period=4, spline_type='linear', filter_std=20):\n",
    "    # Read in path simulation and ground truth files\n",
    "    sim = pd.read_csv(\"../smol_sim/mules/{}.csv\".format(mobile_id))\n",
    "    truth = pd.read_csv(\"../smol_truth/mules/{}.csv\".format(mobile_id))\n",
    "    \n",
    "    # Downsample the simulation.\n",
    "    down_sim = sim.loc[(sim['norm_secs (secs)'].round() % sample_period) == 0]\n",
    "    \n",
    "    # Compile positions of seen gateways.\n",
    "    t = []\n",
    "    sim_x = []\n",
    "    sim_y = []\n",
    "\n",
    "    for index, row in down_sim.iterrows():\n",
    "        t.append(row['norm_secs (secs)'])\n",
    "        sim_x.append(guess[int(row['sensor ID']), 0])\n",
    "        sim_y.append(guess[int(row['sensor ID']), 1])\n",
    "    \n",
    "    \n",
    "    # The goal is to spline. However, splines dont work well with multiple values\n",
    "    # at one point, which happens when we see multiple gateways at the same time.\n",
    "    # Thus, if we see multiple gateways at the same time, we average the positions.\n",
    "    ct = []\n",
    "    cx = []\n",
    "    cy = []\n",
    "\n",
    "    counter = 0\n",
    "    while counter < len(t):\n",
    "        cur_t = t[counter]\n",
    "        cum_x = [sim_x[counter]]\n",
    "        cum_y = [sim_y[counter]]\n",
    "        counter += 1\n",
    "        while counter < len(t) and t[counter] == cur_t:\n",
    "            cum_x.append(sim_x[counter])\n",
    "            cum_y.append(sim_y[counter])\n",
    "            counter += 1\n",
    "        ct.append(cur_t)\n",
    "        cx.append(sum(cum_x) / len(cum_x))\n",
    "        cy.append(sum(cum_y) / len(cum_y))\n",
    "    \n",
    "    \n",
    "    # Calculate our predictions.\n",
    "    fx = interp1d(ct, cx, kind=spline_type)\n",
    "    fy = interp1d(ct, cy, kind=spline_type)\n",
    "    tt = truth.loc[(truth['norm_secs (secs)'] > ct[0]) & \n",
    "                   (truth['norm_secs (secs)'] < ct[-1])]['norm_secs (secs)'].to_numpy()\n",
    "    \n",
    "    # Predict points based on a spline and apply a Gaussian filter to smooth the points.\n",
    "    px = gaussian_filter1d(fx(tt), filter_std)\n",
    "    py = gaussian_filter1d(fy(tt), filter_std)\n",
    "\n",
    "    # Calculate the Euclidean error of the prediction for each truth point.\n",
    "    err = []\n",
    "    for i in range(len(tt)):\n",
    "        ex = px[i] - truth.loc[truth['norm_secs (secs)'] == tt[i]].iloc[0]['x (m)']\n",
    "        ey = py[i] - truth.loc[truth['norm_secs (secs)'] == tt[i]].iloc[0]['y (m)']\n",
    "        err.append(np.linalg.norm([ex, ey]))\n",
    "\n",
    "    \n",
    "    # Plot the results.\n",
    "    # Set some parameters.\n",
    "    truth_marker = 'k,:'\n",
    "    truth_alpha = 0.4\n",
    "    prediction_color = 'g'\n",
    "    prediction_marker = 'g,:'\n",
    "    prediction_alpha = 0.4\n",
    "    error_marker = 'b,-'\n",
    "    gateway_marker = 'rx'\n",
    "    gateway_size = 10\n",
    "    \n",
    "    # Plot x over time.\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.title('X position of {} over time'.format(mobile_id))\n",
    "    plt.xlabel('time (secs)')\n",
    "    plt.ylabel('x (m)')\n",
    "    plt.plot(truth['norm_secs (secs)'], truth['x (m)'], truth_marker, alpha=truth_alpha, label='truth')\n",
    "    plt.plot(tt, px, prediction_marker, alpha=prediction_alpha, label='{} spline prediction'.format(spline_type))\n",
    "    plt.plot(t, sim_x, gateway_marker, markersize=gateway_size, label='seen gateways')\n",
    "    for index, row in truth_df.iterrows():\n",
    "        if index not in known_ids:\n",
    "            plt.Circle((row['x (m)'], row['y (m)']), row['radius (m)'], alpha = 0.4, color='g')\n",
    "            \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot y over time.\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.title('Y position of {} over time'.format(mobile_id))\n",
    "    plt.xlabel('time (secs)')\n",
    "    plt.ylabel('y (m)')\n",
    "    plt.plot(truth['norm_secs (secs)'], truth['y (m)'], truth_marker, alpha=truth_alpha, label='truth')\n",
    "    plt.plot(tt, py, prediction_marker, alpha=prediction_alpha, label='{} spline prediction'.format(spline_type))\n",
    "    plt.plot(t, sim_y, gateway_marker, markersize=gateway_size, label='seen gateways')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the error over time.\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.title(\"Euclidean error of a {} spline approximation for {}\".format(spline_type, mobile_id))\n",
    "    plt.xlabel('time (sec)')\n",
    "    plt.ylabel('error (m)')\n",
    "    plt.plot(tt, err, error_marker, label=\"Euclidean error\")\n",
    "    plt.vlines(ct, 0, 900, colors=prediction_color, alpha=prediction_alpha, label=\"transmission times\")\n",
    "    plt.legend()\n",
    "    plt.plot()\n",
    "    \n",
    "    # Plot the trajectories v.s. the prediction\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.title(\"Prediction v.s. Ground Truth for {}\".format(mobile_id))\n",
    "    plt.xlabel(\"x (m)\")\n",
    "    plt.ylabel(\"y (m)\")\n",
    "    plt.plot(truth['x (m)'], truth['y (m)'], truth_marker, label=\"ground truth trajectory\", alpha=truth_alpha)\n",
    "    plt.plot(px, py, prediction_marker, alpha=prediction_alpha, label=\"predicted trajectory\")\n",
    "    plt.plot(sim_x, sim_y, gateway_marker, markersize=gateway_size, label='seen gateways')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Man, these results make me so sad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prediction(\"011\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
